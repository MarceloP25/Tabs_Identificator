# Relat√≥rio 1 ‚Äî Sistema de Identifica√ß√£o Autom√°tica de Notas e Gera√ß√£o de Tablaturas via Vis√£o Computacional

## 1. Introdu√ß√£o e Objetivo do Projeto

Este projeto visa o desenvolvimento de um sistema de **intelig√™ncia artificial multimodal**, capaz de **analisar v√≠deos de performances de guitarra, viol√£o ou baixo** e identificar, em tempo real, as **notas, acordes e t√©cnicas executadas**, gerando automaticamente uma **tablatura digital** correspondente √† execu√ß√£o.

A abordagem combina **vis√£o computacional** (para entender o posicionamento das m√£os, dedos e o mapeamento do bra√ßo do instrumento) e **an√°lise de √°udio** (para detectar as notas e acordes emitidos). A fus√£o entre essas duas modalidades permite uma interpreta√ß√£o robusta da performance musical, tanto r√≠tmica quanto harm√¥nica e mel√≥dica.

---

## 2. Estrutura Geral do Sistema

O sistema segue um **pipeline em seis etapas principais**, cada uma com objetivos e ferramentas espec√≠ficas:

| Etapa | Descri√ß√£o | Objetivo | Ferramentas Principais |
| --- | --- | --- | --- |
| **1. Entrada e Pr√©-processamento** | Leitura do v√≠deo, extra√ß√£o de frames e √°udio, corre√ß√£o de ilumina√ß√£o e ru√≠do. | Preparar dados padronizados para an√°lise. | OpenCV, MoviePy, Pydub |
| **2. Mapeamento visual do bra√ßo** | Identificar trastes e cordas com base em grid manual e detec√ß√£o autom√°tica. | Construir refer√™ncia espacial do instrumento. | YOLOv8, OpenCV |
| **3. Rastreamento de m√£os e dedos** | Detectar e acompanhar landmarks das m√£os do m√∫sico. | Associar posi√ß√µes visuais √†s notas tocadas. | MediaPipe Hands |
| **4. Processamento de √°udio** | Extrair pitch, notas e acordes sincronizados com o v√≠deo. | Analisar o conte√∫do sonoro da execu√ß√£o. | Librosa |
| **5. Fus√£o multimodal** | Combinar dados visuais e sonoros temporalmente. | Determinar notas exatas e localiza√ß√£o no instrumento. | Pandas, NumPy |
| **6. Gera√ß√£o da tablatura** | Criar tablatura final leg√≠vel. | Transformar dados em partitura textual. | Music21 |

---

## 3. Bases de Dados Referenciadas

Para treinar, calibrar e validar o sistema, s√£o utilizadas as seguintes bases de dados:

| Base | Tipo de Dado | Utiliza√ß√£o |
| --- | --- | --- |
| **GuitarSet (NYU)** | √Åudio multitrack + tablaturas sincronizadas | Treinamento e valida√ß√£o de notas e acordes. |
| **IDMT-SMT-Guitar** | Notas isoladas, t√©cnicas e timbres | Reconhecimento de solos e dedilhados. |
| **MusicNet** | Grava√ß√µes + anota√ß√µes musicais alinhadas | Refinamento do modelo de pitch. |
| **FIID (Fretted Instrument Image Dataset)** | Imagens de guitarras com anota√ß√µes de trastes | Treinamento da detec√ß√£o visual do bra√ßo. |
| **EgoHands / FreiHAND** | Rastreamento de m√£os em v√≠deo | Treinamento do modelo MediaPipe. |

Essas bases cobrem todos os aspectos do sistema ‚Äî da detec√ß√£o visual ao reconhecimento sonoro.

---

## 4. Ferramentas e Bibliotecas

### üîπ 4.1. OpenCV

- **Fun√ß√£o:** manipula√ß√£o de v√≠deo e imagem (captura, processamento, segmenta√ß√£o).
- **Uso no c√≥digo:**
    - Extra√ß√£o de frames (`cv2.VideoCapture`);
    - Convers√£o de cores (`cv2.cvtColor`);
    - Aplica√ß√£o de filtros (Gaussiano, bilateral, mediana);
    - Equaliza√ß√£o de histograma (`cv2.createCLAHE`);
    - Detec√ß√£o de bordas (`cv2.Canny`).
- **Instala√ß√£o:**
    
    ```bash
    pip install opencv-python
    
    ```
    
- **Resultado esperado:** frames tratados com ilumina√ß√£o uniforme e bordas n√≠tidas.

---

### üîπ 4.2. MoviePy

- **Fun√ß√£o:** leitura e manipula√ß√£o de v√≠deos, extra√ß√£o de √°udio.
- **Uso no c√≥digo:**
    
    ```python
    from moviepy.editor import VideoFileClip
    clip = VideoFileClip("video.mp4")
    clip.audio.write_audiofile("audio.wav")
    
    ```
    
- **Resultado esperado:** √°udio sincronizado em `.wav` para an√°lise pelo Librosa.

---

### üîπ 4.3. Pydub

- **Fun√ß√£o:** tratamento e normaliza√ß√£o de √°udio.
- **Uso no c√≥digo:**
    
    ```python
    from pydub import AudioSegment
    audio = AudioSegment.from_wav("audio.wav")
    audio = audio.set_channels(1).set_frame_rate(44100)
    audio.export("audio_clean.wav", format="wav")
    
    ```
    
- **Resultado esperado:** √°udio limpo e padronizado (mono, 44.1kHz).

---

### üîπ 4.4. Librosa

- **Fun√ß√£o:** extra√ß√£o de caracter√≠sticas sonoras (pitch, MFCCs, cromas, acordes).
- **Uso no c√≥digo:** an√°lise no dom√≠nio da frequ√™ncia.
- **Resultado esperado:** lista temporal de notas tocadas.

---

### üîπ 4.5. MediaPipe Hands

- **Fun√ß√£o:** detec√ß√£o e rastreamento 3D das m√£os e dedos.
- **Uso:** reconhecer posi√ß√£o dos dedos sobre o bra√ßo.
- **Resultado:** coordenadas (x, y, z) para cada dedo em cada frame.

---

### üîπ 4.6. YOLOv8

- **Fun√ß√£o:** detec√ß√£o autom√°tica de regi√µes (bra√ßo, trastes, cordas).
- **Uso:** localizar o bra√ßo do instrumento e segmentar trastes.
- **Resultado:** mapa de bounding boxes com classes detectadas.

---

### üîπ 4.7. Music21

- **Fun√ß√£o:** modelagem e exporta√ß√£o da tablatura.
- **Uso:** traduz notas e posi√ß√µes em representa√ß√£o musical textual.
- **Sa√≠da:** `.txt`, `.musicxml` ou `.gp5`.

---

## 5. Passo 1 ‚Äî Pr√©-Processamento e Tratamento Visual

O **Passo 1** √© o ponto de partida do pipeline e envolve a prepara√ß√£o dos dados visuais e sonoros para as etapas seguintes.

---

### 5.1. Subetapas

| Subetapa | Descri√ß√£o | Ferramentas |
| --- | --- | --- |
| **1. Leitura e extra√ß√£o de frames** | Convers√£o do v√≠deo em sequ√™ncia de imagens. | OpenCV |
| **2. Extra√ß√£o e limpeza de √°udio** | Separa√ß√£o do √°udio e padroniza√ß√£o. | MoviePy, Pydub |
| **3. Convers√£o de cor e equaliza√ß√£o** | Ajuste de brilho, contraste e tonalidade. | OpenCV (YCrCb + CLAHE) |
| **4. Redu√ß√£o de ru√≠do** | Filtro bilateral preservando bordas. | OpenCV |
| **5. Detec√ß√£o de bordas** | Realce de contornos de trastes e cordas. | OpenCV (Sobel/Canny) |
| **6. Normaliza√ß√£o e salvamento** | Padroniza√ß√£o e exporta√ß√£o. | NumPy |

---

### 5.2. Pipeline Visual

O tratamento visual √© aplicado a cada frame extra√≠do do v√≠deo, seguindo esta ordem:

1. **Carregamento e convers√£o de cor:**
    
    ```python
    frame = cv2.imread("frame_001.jpg")
    ycrcb = cv2.cvtColor(frame, cv2.COLOR_BGR2YCrCb)
    y, cr, cb = cv2.split(ycrcb)
    
    ```
    
2. **Equaliza√ß√£o adaptativa (CLAHE):**
    
    ```python
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    y_eq = clahe.apply(y)
    ycrcb_eq = cv2.merge((y_eq, cr, cb))
    frame_eq = cv2.cvtColor(ycrcb_eq, cv2.COLOR_YCrCb2BGR)
    
    ```
    
3. **Filtragem de ru√≠do:**
    
    ```python
    smooth = cv2.bilateralFilter(frame_eq, d=9, sigmaColor=75, sigmaSpace=75)
    
    ```
    
4. **Realce de bordas:**
    
    ```python
    edges = cv2.Canny(smooth, 50, 150)
    
    ```
    
5. **Combina√ß√£o ponderada:**
    
    ```python
    enhanced = cv2.addWeighted(smooth, 0.8, cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR), 0.2, 0)
    
    ```
    
6. **Normaliza√ß√£o e salvamento:**
    
    ```python
    norm = cv2.normalize(enhanced, None, 0, 255, cv2.NORM_MINMAX)
    cv2.imwrite("data/processed/frames_enhanced/frame_001.jpg", norm)
    
    ```
    

---

### 5.3. Resultados e M√©tricas

Cada frame tratado gera:

- **Imagem aprimorada:** com contraste uniforme e bordas bem definidas.
- **Metadados:** armazenando brilho m√©dio, contraste e densidade de bordas (para calibrar o CLAHE).
- **Logs:** um CSV com as m√©tricas por frame, permitindo autocalibra√ß√£o futura.

Essas imagens alimentam diretamente o **Passo 2**, que far√° o reconhecimento do bra√ßo e a gera√ß√£o do grid.

---

### Estrutura de Diret√≥rios

```
data/
 ‚îú‚îÄ‚îÄ raw/
 ‚îÇ   ‚îî‚îÄ‚îÄ video_original.mp4
 ‚îú‚îÄ‚îÄ processed/
 ‚îÇ   ‚îú‚îÄ‚îÄ frames/
 ‚îÇ   ‚îú‚îÄ‚îÄ frames_enhanced/
 ‚îÇ   ‚îú‚îÄ‚îÄ audio/
 ‚îÇ   ‚îú‚îÄ‚îÄ metadata.json
 ‚îÇ   ‚îî‚îÄ‚îÄ logs/

```

---

## 6. Pr√≥ximos Passos (Passo 2)

O **Passo 2 ‚Äî Mapeamento visual do bra√ßo** ter√° como objetivo:

- Detectar o bra√ßo e trastes com YOLOv8;
- Calibrar manualmente um grid de refer√™ncia;
- Associar trastes √†s notas (em Hz e nomes musicais);
- Preparar o mapa para a fus√£o com o √°udio e rastreamento de m√£os.